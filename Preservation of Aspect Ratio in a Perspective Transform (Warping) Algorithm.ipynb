{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When a photograph of a square is taken from a tilted angle, and on further perspective transform, one usually observes that a trapezium gets converted to a rectange (or a square in some cases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An accurate algorithm tries to retain the aspect ratio of the original square as much as possible, unless in certain circumstances owing to the angle of the image, it is very hard to retain the aspect ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, two different algorithms which demonstrate the difference in the aspect ratio of the perspective-transformed images from the actual image, along with the extent of the deviation is presented. The algorithms are compared with the performance of warping which is done by a Cam Scanner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the sake of illustration, a 10 cm * 10 cm square is drawn on a graph sheet (so the actual aspect ratio is 1.00). The aspect ratios of the warped images is assessed for their deviation from 1.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import path\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mpld3\n",
    "from mpld3 import plugins\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "#from skimage import segmentation\n",
    "from skimage import filters\n",
    "#from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage import util\n",
    "\n",
    "from sklearn import cluster\n",
    "\n",
    "from scipy.spatial import ConvexHull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDetection:\n",
    "    \n",
    "    def __init__(self,imgFile,farmWidth=3.0):\n",
    "        self.imgFile = imgFile\n",
    "        self.farmWidth = farmWidth\n",
    "        \n",
    "    def read(self,invert=False):\n",
    "        img = io.imread(self.imgFile,as_gray=True)\n",
    "        img = util.img_as_float(img)\n",
    "        if invert:\n",
    "            img = util.invert(img)    \n",
    "        self.img = img\n",
    "        self.img_x, self.img_y = img.shape\n",
    "        return img\n",
    "    \n",
    "    def readRGB(self):\n",
    "        self.rgbimg = io.imread(self.imgFile)\n",
    "        return self.rgbimg\n",
    "        \n",
    "    def rescale(self,img,scale):\n",
    "        if self.img is not None:\n",
    "            self.scale = np.float(scale)\n",
    "            self.img_rs = transform.rescale(self.img,self.scale,multichannel=False)\n",
    "            return self.img_rs\n",
    "            \n",
    "    def plotImg(self,img,title=None,cmap='gray',figsize=(15,15)):\n",
    "        fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "        #ax.axis('off')\n",
    "        ax.imshow(img,cmap=cmap)\n",
    "        if title:\n",
    "            ax.set_title(title,fontsize=20)\n",
    "        plt.show()\n",
    "\n",
    "    def plotHist(self,img,title=None):\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.hist(img.ravel(), bins=32, range=[0.0, 1.2])\n",
    "        ax.set_xlim(0.0,1.2);\n",
    "        if title:\n",
    "            ax.set_title(title,fontsize=20)\n",
    "        plt.show()\n",
    "        \n",
    "    def plotCoords(self,coords,s=1,c='r',fmt='ro'):\n",
    "        fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "        ax.plot(coords[:,0],coords[:,1],fmt)\n",
    "        plt.show()        \n",
    "        \n",
    "    def gaussFilter(self,img,sigma=1):\n",
    "        return filters.gaussian(img,sigma)\n",
    "    \n",
    "    def getLocalThresh(self,img, block_size=101, offset=-0.05):\n",
    "        return filters.threshold_local(img,block_size=block_size, offset=offset) \n",
    "    \n",
    "    def binarizeThresh(self,img,thresh):\n",
    "        return img>thresh\n",
    "    \n",
    "    def blurThicken(self,img,sigma=1):\n",
    "        img_blur = self.gaussFilter(img,sigma)\n",
    "        return self.binarizeThresh(img_blur,0)\n",
    "    \n",
    "    def applyBinMask(self,img,binMask):\n",
    "        return np.multiply(img,binMask)\n",
    "    \n",
    "    def getThickBinMask(self,img,initSigma=1,block_size=101,offset=-0.05,finalSigma=1):\n",
    "        img_gauss = self.gaussFilter(img,sigma=initSigma)\n",
    "        img_thresh = self.getLocalThresh(img_gauss,block_size=block_size,offset=offset)\n",
    "        img_bin = self.binarizeThresh(img_gauss,img_thresh)\n",
    "        img_bin_thick = imgD.blurThicken(img_bin,sigma=finalSigma)\n",
    "        return img_bin_thick\n",
    "    \n",
    "    def getCoords_Img(self,img):\n",
    "        numRow, numCol = img.shape\n",
    "        ygrid, xgrid = np.mgrid[:numRow, :numCol]\n",
    "        coords = np.vstack((xgrid.ravel(), ygrid.ravel())).T\n",
    "        return coords\n",
    "    \n",
    "    def getCoords_binImg(self,img):\n",
    "        a = np.ones(img.shape)\n",
    "        x_i = np.linspace(0,img.shape[0]-1,img.shape[0]).astype('uint')\n",
    "        y_i = np.linspace(0,img.shape[1]-1,img.shape[1]).astype('uint')\n",
    "        x_mask = np.multiply(a.T,x_i).T\n",
    "        y_mask = np.multiply(a,y_i)\n",
    "        x_coords = np.multiply(a,x_mask)\n",
    "        y_coords = np.multiply(a,y_mask)\n",
    "        all_coords = np.vstack((x_coords.flatten(),y_coords.flatten())).T.astype('uint')\n",
    "        res = all_coords[img.flatten().astype('uint8')==1]\n",
    "        return res\n",
    "    \n",
    "    def applyDBSCAN(self,coords,eps=10, min_samples=30):\n",
    "        dbscan = cluster.DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        dbscan.fit(coords)\n",
    "        predictions = dbscan.labels_\n",
    "        return predictions\n",
    "    \n",
    "    def getGroupNums(self,groups,include0=True):\n",
    "        if include0:\n",
    "            return np.unique(groups)\n",
    "        else:\n",
    "            all_groups = np.unique(groups)\n",
    "            index = np.where(all_groups == 1)\n",
    "            return all_groups[index[0][0]:]\n",
    "    \n",
    "    def applyLabels_binImg(self,img,coords,labels):\n",
    "        label_mask = np.zeros(img.shape).astype('uint')\n",
    "        for i in range(len(coords)):\n",
    "            row,col = coords[i]\n",
    "            label_mask[row][col]=labels[i]\n",
    "        return label_mask\n",
    "    \n",
    "    def upscale_binMask(self,img,rs_mask,scale):\n",
    "        rs_mask_upscale = transform.rescale(rs_mask,1.0/scale,multichannel=False)\n",
    "        full_mask = np.zeros(img.shape)\n",
    "        full_mask[:rs_mask_upscale.shape[0],:rs_mask_upscale.shape[1]] = rs_mask_upscale\n",
    "        return full_mask\n",
    "    \n",
    "    def applyConvexHull_Groups(self,coords,groups):\n",
    "        groupNums = np.unique(groups)\n",
    "\n",
    "        groupCoords = []\n",
    "        groupHulls = []\n",
    "        #img_rs_groups = []\n",
    "        groupVertices = []\n",
    "\n",
    "        for groupNum in groupNums:\n",
    "            thisCoords = []\n",
    "            for i in range(len(coords)):\n",
    "                if groups[i]==groupNum:\n",
    "                    thisCoords.append(coords[i])\n",
    "            groupCoords.append(np.array(thisCoords))\n",
    "            thisHull = ConvexHull(thisCoords)\n",
    "            groupHulls.append(thisHull)\n",
    "            #thisImg = np.multiply(img, img_groups==groupNum)\n",
    "            #img_rs_groups.append(thisImg)\n",
    "            thisVertices = []\n",
    "            for vertex in thisHull.vertices:\n",
    "                thisVertices.append([thisCoords[vertex][1],thisCoords[vertex][0]])\n",
    "            groupVertices.append(np.array(thisVertices))\n",
    "            \n",
    "        return groupCoords,groupHulls,groupVertices\n",
    "    \n",
    "    def getImg_GroupMask(self,img,img_groups,groupNum):\n",
    "        return np.multiply(img, img_groups==groupNum)    \n",
    "    \n",
    "    def plotRGBImg_GroupsRS(self,rgbimg,groups,groupNums,groupVertices,scale,\n",
    "                            fmt='k-',linewidth=1,annotate=True):\n",
    "        fig, ax = plt.subplots(1,1,figsize=(15, 15))\n",
    "        ax.axis('off')\n",
    "        ax.imshow(rgbimg)\n",
    "        for groupNum in groupNums:\n",
    "            ax.fill(groupVertices[groupNum][:,0]/scale,\n",
    "                    groupVertices[groupNum][:,1]/scale,\n",
    "                    fmt,linewidth=linewidth,fill=False)\n",
    "            if annotate:\n",
    "                ax.annotate(groupNum,xy=(groupVertices[groupNum][0][0]/scale,\n",
    "                                         groupVertices[groupNum][0][1]/scale))\n",
    "        plt.show()        \n",
    "         \n",
    "    def plotRGBImg_var(self,rgbimg,groups,groupNums,groupVertices,scale, fmt='k-',linewidth=1,annotate=True):\n",
    "        fig, ax = plt.subplots(1,1,figsize=(15, 15))\n",
    "        ax.axis('off')\n",
    "        ax.imshow(rgbimg)\n",
    "        for groupNum in groupNums:\n",
    "            if annotate:\n",
    "                ax.annotate(groupNum,xy=(groupVertices[groupNum][0][0]/scale,\n",
    "                                         groupVertices[groupNum][0][1]/scale))\n",
    "        plt.show()        \n",
    "                 \n",
    "            \n",
    "            \n",
    "    def getGroupDetails(self,img,\n",
    "                        initSigma=1,block_size=101,offset=-0.05,finalSigma=1,\n",
    "                        eps=10,min_samples=30):\n",
    "        img_bin_thick = self.getThickBinMask(img,initSigma=initSigma,\n",
    "                                             block_size=block_size,\n",
    "                                             offset=offset,\n",
    "                                             finalSigma=finalSigma)\n",
    "        coords = self.getCoords_binImg(img_bin_thick)\n",
    "        groups = self.applyDBSCAN(coords,\n",
    "                                  eps=eps,\n",
    "                                  min_samples=min_samples)\n",
    "        groupCoords,groupHulls,groupVertices = self.applyConvexHull_Groups(coords,groups)\n",
    "        groupLabel_Mask = self.applyLabels_binImg(img,coords,groups)\n",
    "        return groups,groupCoords,groupHulls,groupVertices,groupLabel_Mask\n",
    "\n",
    "    \n",
    "    def getMaskSubImg(self,img,scale,groupVertices,groupNum):\n",
    "        scaledVertices = np.array(groupVertices[groupNum])/scale\n",
    "        groupPath = path.Path(scaledVertices,closed=False)\n",
    "        coords = self.getCoords_Img(img)\n",
    "        mask = groupPath.contains_points(coords)\n",
    "        mask = mask.reshape(img.shape)\n",
    "        return mask\n",
    "        \n",
    "    \n",
    "    def getSubImg(self,img,scale,groupVertices,groupNum,applyMask=True):\n",
    "        min_x = int(np.min(groupVertices[groupNum][:,0])/scale)\n",
    "        max_x = int(np.max(groupVertices[groupNum][:,0])/scale)\n",
    "        min_y = int(np.min(groupVertices[groupNum][:,1])/scale)\n",
    "        max_y = int(np.max(groupVertices[groupNum][:,1])/scale)\n",
    "        if applyMask:\n",
    "            mask = self.getMaskSubImg(img,scale,groupVertices,groupNum)\n",
    "            masked_img = self.applyBinMask(img,mask)\n",
    "            subimg = masked_img[min_y:max_y,min_x:max_x]\n",
    "        else:\n",
    "            subimg = img[min_y:max_y,min_x:max_x]\n",
    "        return subimg\n",
    "    \n",
    "    def fitLine_imgBin(self,img,coords,plot=True):\n",
    "        if len(coords)==0:\n",
    "            return 0,0\n",
    "        \n",
    "        model = measure.LineModelND()\n",
    "        model.estimate(coords)\n",
    "\n",
    "        line_x = np.arange(0, img.shape[0])\n",
    "        line_y = model.predict_y(line_x)\n",
    "\n",
    "        coeff = (line_y[-1]-line_y[0])/(line_x[-1]-line_x[0])\n",
    "        intercept = model.predict_y([0])\n",
    "        \n",
    "        if plot:\n",
    "            fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "            ax.plot(coords[:,0],coords[:,1],'ko')\n",
    "            ax.plot(line_x,line_y,'r-',linewidth=4)\n",
    "            plt.show()        \n",
    "        \n",
    "        return coeff,intercept\n",
    "    \n",
    "    def rotateImg(self,img,coeff):\n",
    "        return transform.rotate(img,-np.degrees(np.arctan(coeff)),resize=True)\n",
    "    \n",
    "    def rotateSubImg(self,img,\n",
    "                     plotFit=True,\n",
    "                    initSigma=1,block_size=101,offset=-0.05,finalSigma=1):\n",
    "        img_bin_thick = self.getThickBinMask(img,\n",
    "                                             initSigma=initSigma,\n",
    "                                             block_size=block_size,\n",
    "                                             offset=offset,\n",
    "                                             finalSigma=finalSigma)\n",
    "        img_coords = self.getCoords_binImg(img_bin_thick)\n",
    "        coeff,intercept = self.fitLine_imgBin(img_bin_thick,img_coords,plot=plotFit)\n",
    "        return self.rotateImg(img,coeff)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def cropMask(self,img,mask):\n",
    "        x_i = np.argmax(mask,axis=0)\n",
    "        x_inz = np.nonzero(x_i)\n",
    "        y_i = np.argmax(mask,axis=1)\n",
    "        y_inz = np.nonzero(y_i)\n",
    "        if ((len(x_inz[0])==0 or len(y_inz[0])==0)):\n",
    "            return np.array([[0]])\n",
    "        min_x = x_inz[0][0]\n",
    "        max_x = x_inz[0][-1]\n",
    "        img_w = mask.shape[1]\n",
    "        min_y = y_inz[0][0]\n",
    "        max_y = y_inz[0][-1]\n",
    "        img_h = mask.shape[0]\n",
    "        crops = ((min_y,img_h-max_y-1),(min_x,img_w-max_x-1))\n",
    "        return util.crop(img,crops)\n",
    "    \n",
    "    def cropSubImg(self,img,sigma=3,thresh=0.7):\n",
    "        img_gauss = self.gaussFilter(img,sigma=sigma)\n",
    "        img_bin = self.binarizeThresh(img_gauss,thresh=thresh)\n",
    "        return self.cropMask(img,img_bin)   \n",
    "    \n",
    "    def getAspectRatio(self,img):\n",
    "        aspectRatio = np.float(img.shape[0]/img.shape[1])\n",
    "        if aspectRatio == 0:\n",
    "            aspectRatio = 1\n",
    "        return aspectRatio\n",
    "    \n",
    "    def getAreaRatio(self,img,\n",
    "                     initSigma=1,block_size=101,offset=-0.05,finalSigma=1):\n",
    "        img_bin_thick = self.getThickBinMask(img,\n",
    "                                    initSigma=initSigma,\n",
    "                                    block_size=block_size,\n",
    "                                    offset=offset,\n",
    "                                    finalSigma=finalSigma)\n",
    "        actualArea = np.sum(img_bin_thick)\n",
    "        imgArea = img.shape[0]*img.shape[1]\n",
    "        return np.float(actualArea/imgArea)\n",
    "    \n",
    "    def getSizeRatio(self,img,subimg):\n",
    "        img_x, img_y = img.shape\n",
    "        subimg_x, subimg_y = subimg.shape\n",
    "        return (subimg_x*subimg_y)/(img_x*img_y)\n",
    "    \n",
    "    def check_img_is_farm(self,img):\n",
    "        sizeRatio = self.getSizeRatio(self.img,img)\n",
    "        isNormalSize = sizeRatio > 0.001 and sizeRatio < 0.025\n",
    "        aspectRatio = self.getAspectRatio(img)\n",
    "        isRect = aspectRatio>2.5 or aspectRatio<1.0/2.5\n",
    "        isFarm = isNormalSize and isRect\n",
    "        return isFarm\n",
    "    \n",
    "    def check_farm_is_full(self,img):\n",
    "        if self.check_img_is_farm(img):\n",
    "            return self.getAreaRatio(img)>0.5\n",
    "        return False\n",
    "    \n",
    "    def get_farm_length(self,img):\n",
    "        if self.check_img_is_farm(img):\n",
    "            aspectRatio = self.getAspectRatio(img)\n",
    "            if aspectRatio>1:\n",
    "                farmLength = self.farmWidth*aspectRatio\n",
    "            else:\n",
    "                farmLength = self.farmWidth/aspectRatio\n",
    "            return farmLength\n",
    "        return 0.0\n",
    "    \n",
    "    def get_farm_area(self,img):\n",
    "        if self.check_img_is_farm(img):\n",
    "            return self.farmWidth*self.get_farm_length(img)\n",
    "        return 0.0\n",
    "    \n",
    "    def determineOptimumThresh_Crop(self,img,sigma=3):\n",
    "        a = np.linspace(0.0,100,21)\n",
    "        b = ((-1)**(a%2))*a/4\n",
    "        thresholds = 0.75+b/100\n",
    "        threshs = []\n",
    "        metric = []\n",
    "        #thresholds = np.linspace(0.5,1.0,20)\n",
    "        for thresh in thresholds:\n",
    "            threshs.append(thresh)\n",
    "            subimg = self.cropSubImg(img,sigma=sigma,thresh=thresh)\n",
    "            areaRatio = self.getAreaRatio(subimg)\n",
    "            metric.append(subimg.shape[0]*subimg.shape[1]*areaRatio)\n",
    "        optThresh = threshs[np.argmax(metric)]\n",
    "        return optThresh\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE - FROM HERE - THE ADDITIONAL CODES COMPLIED BY PRANEETH - BEGIN\n",
    "#LOT OF FUNCTIONS ARE IMPORTED READILY FROM EXISTING CODE\n",
    "\n",
    "def minimum_bounding_rectangle(temp):\n",
    "    \"\"\"\n",
    "    Find the smallest bounding rectangle for a set of points.\n",
    "    Returns a set of points representing the corners of the bounding box.\n",
    "\n",
    "    :param points: an nx2 matrix of coordinates\n",
    "    :rval: an nx2 matrix of coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    from scipy.spatial import ConvexHull\n",
    "\n",
    "    from scipy.ndimage.interpolation import rotate\n",
    "    pi2 = np.pi/2.\n",
    "\n",
    "    # get the convex hull for the points\n",
    "    #hull_points = points[ConvexHull(points).vertices]\n",
    "    \n",
    "    hull_points = temp\n",
    "    \n",
    "    # calculate edge angles\n",
    "    edges = np.zeros((len(hull_points)-1, 2))\n",
    "    edges = hull_points[1:] - hull_points[:-1]\n",
    "\n",
    "    angles = np.zeros((len(edges)))\n",
    "    angles = np.arctan2(edges[:, 1], edges[:, 0])\n",
    "\n",
    "    angles = np.abs(np.mod(angles, pi2))\n",
    "    angles = np.unique(angles)\n",
    "\n",
    "    # find rotation matrices\n",
    "    # XXX both work\n",
    "    rotations = np.vstack([\n",
    "        np.cos(angles),\n",
    "        np.cos(angles-pi2),\n",
    "        np.cos(angles+pi2),\n",
    "        np.cos(angles)]).T\n",
    "#     rotations = np.vstack([\n",
    "#         np.cos(angles),\n",
    "#         -np.sin(angles),\n",
    "#         np.sin(angles),\n",
    "#         np.cos(angles)]).T\n",
    "    rotations = rotations.reshape((-1, 2, 2))\n",
    "\n",
    "    # apply rotations to the hull\n",
    "    rot_points = np.dot(rotations, hull_points.T)\n",
    "\n",
    "    # find the bounding points\n",
    "    min_x = np.nanmin(rot_points[:, 0], axis=1)\n",
    "    max_x = np.nanmax(rot_points[:, 0], axis=1)\n",
    "    min_y = np.nanmin(rot_points[:, 1], axis=1)\n",
    "    max_y = np.nanmax(rot_points[:, 1], axis=1)\n",
    "\n",
    "    # find the box with the best area\n",
    "    areas = (max_x - min_x) * (max_y - min_y)\n",
    "    best_idx = np.argmin(areas)\n",
    "\n",
    "    # return the best box\n",
    "    x1 = max_x[best_idx]\n",
    "    x2 = min_x[best_idx]\n",
    "    y1 = max_y[best_idx]\n",
    "    y2 = min_y[best_idx]\n",
    "    r = rotations[best_idx]\n",
    "\n",
    "    rval = np.zeros((4, 2))\n",
    "    rval[0] = np.dot([x1, y2], r)\n",
    "    rval[1] = np.dot([x2, y2], r)\n",
    "    rval[2] = np.dot([x2, y1], r)\n",
    "    rval[3] = np.dot([x1, y1], r)\n",
    "\n",
    "    rval2 = np.array(rval, np.int32)\n",
    "    return(rval2)\n",
    "\n",
    "\n",
    "\n",
    "def polygon_area(x1,y1):\n",
    "    \n",
    "    #computes the area of a polygon given the coordinates of the polygon\n",
    "    \n",
    "    # coordinate shift\n",
    "    x = np.array(x1)\n",
    "    y = np.array(y1)\n",
    "    x_ = x - x.mean()\n",
    "    y_ = y - y.mean()\n",
    "    # everything else is the same as maxb's code\n",
    "    correction = x_[-1] * y_[0] - y_[-1]* x_[0]\n",
    "    main_area = np.dot(x_[:-1], y_[1:]) - np.dot(y_[:-1], x_[1:])\n",
    "    return 0.5*np.abs(main_area + correction)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def max_index_compute(temp):\n",
    "    #given an input of convex hull points - this function outputs the collection of 4 points\n",
    "    #which are the set of points of the quadrilateral - which are the best representative\n",
    "    #of a large cluster of points\n",
    "        \n",
    "        \n",
    "    cvX = temp[:,0]\n",
    "    cvY = temp[:,1]\n",
    "\n",
    "    numberOfPoints = len(cvX)\n",
    "    maxArea = 0;\n",
    "    \n",
    "    for k1 in range(numberOfPoints):\n",
    "      for k2 in range(numberOfPoints):\n",
    "        for k3 in range(numberOfPoints):\n",
    "          for k4 in range(numberOfPoints):\n",
    "                    verticesX = [cvX[k1], cvX[k2], cvX[k3], cvX[k4]]\n",
    "                    verticesY = [cvY[k1], cvY[k2], cvY[k3], cvY[k4]]\n",
    "                    #thisArea = PolyArea(verticesX, verticesY)\n",
    "                    thisArea = polygon_area(verticesX, verticesY)\n",
    "                    if thisArea > maxArea:\n",
    "                      maxArea = thisArea\n",
    "                      indexesAtmax = [k1, k2, k3, k4]\n",
    "    \n",
    "    op = temp[indexesAtmax]\n",
    "    return(op)\n",
    "\n",
    "\n",
    "\n",
    "def order_points(pts):\n",
    "    \n",
    "    #given an input of four points, this function returns the points ordered in a clockwise\n",
    "    #manner\n",
    "    \n",
    "    from scipy.spatial import distance as dist\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import scipy\n",
    "    \n",
    "    # sort the points based on their x-coordinates\n",
    "    xSorted = pts[np.argsort(pts[:, 0]), :]\n",
    "\n",
    "    # grab the left-most and right-most points from the sorted\n",
    "    # x-roodinate points\n",
    "    leftMost = xSorted[:2, :]\n",
    "    rightMost = xSorted[2:, :]\n",
    "\n",
    "    # now, sort the left-most coordinates according to their\n",
    "    # y-coordinates so we can grab the top-left and bottom-left\n",
    "    # points, respectively\n",
    "    leftMost = leftMost[np.argsort(leftMost[:, 1]), :]\n",
    "    (tl, bl) = leftMost\n",
    "\n",
    "    # now that we have the top-left coordinate, use it as an\n",
    "    # anchor to calculate the Euclidean distance between the\n",
    "    # top-left and right-most points; by the Pythagorean\n",
    "    # theorem, the point with the largest distance will be\n",
    "    # our bottom-right point\n",
    "    D = dist.cdist(tl[np.newaxis], rightMost, \"euclidean\")[0]\n",
    "    (br, tr) = rightMost[np.argsort(D)[::-1], :]\n",
    "\n",
    "    # return the coordinates in top-left, top-right,\n",
    "    # bottom-right, and bottom-left order\n",
    "    return np.array([tl, tr, br, bl], dtype=\"float32\")\n",
    "\n",
    "\n",
    "\n",
    "def asp_ratio(img, ordered_points_int, center_coordinates):\n",
    "    \n",
    "    #This function is adapted from \n",
    "    #https://www.microsoft.com/en-us/research/publication/whiteboard-scanning-image-enhancement/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Fzhang%2Fpapers%2Ftr03-39.pdf\n",
    "    #assuming a pinhole camera model, it is possible to calculate the aspect ratio for a projected rectangle (but not the scale, unsurprisingly). Essentially, one can solve for the focal length, then get the aspect ratio\n",
    "    \n",
    "    #the problem with this method is 1/0 error in focal length occurs at times causing blowing up\n",
    "    #moreover the aspect ratios which are output are quite varied\n",
    "    #the pinhole model does not work for this case.\n",
    "    \n",
    "    import math\n",
    "    import scipy\n",
    "    from scipy.spatial import distance as dist\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "\n",
    "    coordA = ordered_points_int[0]\n",
    "    coordB = ordered_points_int[1]\n",
    "    coordC= ordered_points_int[3]\n",
    "    coordD= ordered_points_int[2]\n",
    "    \n",
    "    p = (coordA, coordB, coordC, coordD)\n",
    "    \n",
    "    v0 = center_coordinates[1]\n",
    "    u0 = center_coordinates[0]\n",
    "    \n",
    "    \n",
    "    #detected corners on the original image\n",
    "    \n",
    "    #widths and heights of the projected image\n",
    "    w1 = scipy.spatial.distance.euclidean(p[0],p[1])\n",
    "    w2 = scipy.spatial.distance.euclidean(p[2],p[3])\n",
    "    \n",
    "    h1 = scipy.spatial.distance.euclidean(p[0],p[2])\n",
    "    h2 = scipy.spatial.distance.euclidean(p[1],p[3])\n",
    "    \n",
    "    w = max(w1,w2)\n",
    "    h = max(h1,h2)\n",
    "    \n",
    "    #visible aspect ratio\n",
    "    ar_vis = float(w)/float(h)\n",
    "    \n",
    "    #make numpy arrays and append 1 for linear algebra\n",
    "    m1 = np.array((p[0][0],p[0][1],1)).astype('float32')\n",
    "    m2 = np.array((p[1][0],p[1][1],1)).astype('float32')\n",
    "    m3 = np.array((p[2][0],p[2][1],1)).astype('float32')\n",
    "    m4 = np.array((p[3][0],p[3][1],1)).astype('float32')\n",
    "    \n",
    "    #calculate the focal disrance\n",
    "    k2 = np.dot(np.cross(m1,m4),m3) / np.dot(np.cross(m2,m4),m3)\n",
    "    k3 = np.dot(np.cross(m1,m4),m2) / np.dot(np.cross(m3,m4),m2)\n",
    "    \n",
    "    n2 = k2 * m2 - m1\n",
    "    n3 = k3 * m3 - m1\n",
    "    \n",
    "    n21 = n2[0]\n",
    "    n22 = n2[1]\n",
    "    n23 = n2[2]\n",
    "    \n",
    "    n31 = n3[0]\n",
    "    n32 = n3[1]\n",
    "    n33 = n3[2]\n",
    "    \n",
    "    f = math.sqrt(np.abs( (1.0/(n23*n33)) * ((n21*n31 - (n21*n33 + n23*n31)*u0 + n23*n33*u0*u0) + (n22*n32 - (n22*n33+n23*n32)*v0 + n23*n33*v0*v0))))\n",
    "    \n",
    "    A = np.array([[f,0,u0],[0,f,v0],[0,0,1]]).astype('float32')\n",
    "    \n",
    "    At = np.transpose(A)\n",
    "    Ati = np.linalg.inv(At)\n",
    "    Ai = np.linalg.inv(A)\n",
    "    \n",
    "    #calculate the real aspect ratio\n",
    "    ar_real = math.sqrt(np.dot(np.dot(np.dot(n2,Ati),Ai),n2)/np.dot(np.dot(np.dot(n3,Ati),Ai),n3))\n",
    "    \n",
    "    if ar_real < ar_vis:\n",
    "        try:\n",
    "            W = int(w)\n",
    "            H = int(W / ar_real)\n",
    "        except:\n",
    "            H = 1\n",
    "    else:\n",
    "        H = int(h)\n",
    "        W = int(ar_real * H)\n",
    "    \n",
    "    pts1 = np.array(p).astype('float32')\n",
    "    pts2 = np.float32([[0,0],[W,0],[0,H],[W,H]])\n",
    "    \n",
    "    #project the image with the new w/h\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    dst = cv2.warpPerspective(img,M,(W,H))\n",
    "    #plt.imshow(dst)\n",
    "    \n",
    "    #cv2.imwrite('orig.png',img)\n",
    "    #cv2.imwrite('proj.png',dst)\n",
    "    \n",
    "    return(ar_real,dst)\n",
    "\n",
    "def asp_ratio_simpler(img, ordered_points_int):\n",
    "\n",
    "    #this is a straightforward method to apply warping - not much of brain is used as far as the aspect ratio is concerned\n",
    "    #aspect ratio is not accurately computed\n",
    "    \n",
    "    \n",
    "    import math\n",
    "    import scipy\n",
    "    from scipy.spatial import distance as dist\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "\n",
    "    (tl, tr, br, bl) = ordered_points_int\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    # ...and now for the height of our new image\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    # take the maximum of the width and height values to reach\n",
    "    # our final dimensions\n",
    "    \n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # construct our destination points which will be used to\n",
    "      \n",
    "    orig_new = np.array([ordered_points_int[0], ordered_points_int[1], ordered_points_int[3], ordered_points_int[2]],dtype = \"float32\" )\n",
    "    dst_new = np.array([\t[0, 0], [maxWidth - 1, 0], [0, maxHeight - 1], [maxWidth - 1, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(orig_new, dst_new)\n",
    "        \n",
    "    warp = cv2.warpPerspective(img, M, (maxWidth, maxHeight))\n",
    "    as_ratio = maxWidth/maxHeight\n",
    "    \n",
    "    return(as_ratio, warp)\n",
    "    \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImg_trial(img,title=None,cmap='gray',figsize=(10,10)):\n",
    "    \n",
    "        fig, ax = plt.subplots(1,1,figsize=figsize)\n",
    "        #ax.axis('off')\n",
    "        ax.imshow(img,cmap=cmap)\n",
    "        if title:\n",
    "            ax.set_title(title,fontsize=20)\n",
    "        plugins.connect(fig, plugins.MousePosition(fontsize=14))\n",
    "\n",
    "        mpld3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgFile = '/Users/praneeth/Downloads/Image Processing/Updates_in_Sep2020/images_from_video/DRONE_TRANSECT_AR_16SEP19 16.png'\n",
    "farmWidth = 3.0 # meters\n",
    "tubenetPerMeter = 10 # meters\n",
    "\n",
    "imgD = ImageDetection(imgFile,farmWidth)\n",
    "img = imgD.read(invert=False)\n",
    "imgrgb = imgD.readRGB()\n",
    "imgrgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotImg_trial(imgrgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following image shows a graph sheet with a square drawn on it which is a photographed from a tilted angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farmWidth = 3.0 # meters\n",
    "tubenetPerMeter = 10 # meters\n",
    "\n",
    "imgD = ImageDetection(imgFile,farmWidth)\n",
    "img = imgD.read(invert=False)\n",
    "imgrgb = imgD.readRGB()\n",
    "scale = 1.0/4.0\n",
    "img_rs = imgD.rescale(img,scale)\n",
    "imgD.plotImg(imgrgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.array([[58,291], [863, 267], [894,1100],[65,1100]], np.int32)\n",
    "\n",
    "q2 = np.array([[152, 281], [753, 262], [788,900], [133, 898]], np.int32)\n",
    "\n",
    "q3 = np.array([[218, 36], [743, 25], [769, 533], [190, 535]], np.int32)\n",
    "\n",
    "q4 = np.array([[292, 56], [629, 48], [657, 286], [247, 291]], np.int32)\n",
    "\n",
    "q5 = np.array([[324,5], [637,3], [656,198], [283,200]], np.int32)\n",
    "\n",
    "q6 = np.array([[228, 790], [395, 790], [391, 971], [216, 973]], np.int32)\n",
    "\n",
    "q7 = np.array([[303, 276], [505, 281], [501, 469], [289,458]], np.int32)\n",
    "\n",
    "q8 = np.array([[367, 28], [482, 28], [480,134], [364,136]], np.int32)\n",
    "\n",
    "q9 = np.array([[201, 195 ], [1130, 181     ], [ 1130, 1080     ],[222,1090     ]], np.int32)\n",
    "q10 = np.array([[120, 621    ], [747, 633      ], [ 730, 1290    ],[111,1265     ]], np.int32)\n",
    "q11 = np.array([[112, 108    ], [756, 141      ], [ 738, 815     ],[46, 782     ]], np.int32)\n",
    "q12 = np.array([[265, 261    ], [549, 274      ], [542, 564      ],[246, 541     ]], np.int32)\n",
    "\n",
    "q13 = np.array([[209, 234    ], [453, 240      ], [457, 493      ],[209, 487     ]], np.int32)\n",
    "q14 = np.array([[292, 361    ], [648, 377      ], [654, 760    ],[292, 737    ]], np.int32)\n",
    "q15 = np.array([[444, 511    ], [970, 515      ], [975, 1020    ],[434, 1020 ]], np.int32)\n",
    "q16 = np.array([[195, 212    ], [1220, 228     ], [1180, 1280   ],[120, 1240    ]], np.int32)\n",
    "\n",
    "q17 = np.array([[696, 181   ], [ 1605, 194   ], [ 1590, 1100  ],[679, 1070   ]], np.int32)\n",
    "q18 = np.array([[510, 139   ], [ 1380, 177   ], [ 1510, 1150  ],[548, 1040   ]], np.int32)\n",
    "q19 = np.array([[586, 176   ], [ 1460, 163   ], [ 1590, 1080  ],[660, 1030   ]], np.int32)\n",
    "q20 = np.array([[912, 1030   ], [1880, 1130    ], [1630, 2060   ],[749, 2050   ]], np.int32)\n",
    "q21 = np.array([[612, 562   ], [1370, 504    ], [1260, 1300  ],[455, 1370   ]], np.int32)\n",
    "\n",
    "\n",
    "q = [q1, q2, q3, q4, q5, q6, q7, q8, q9, q10, q11, q12, q13, q14, q15, q16, q17, q18, q19, q20, q21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "quadrangle_vertices = q[4]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord1min = min(quadrangle_vertices[:,0])\n",
    "coord1max = max(quadrangle_vertices[:,0])\n",
    "coord2min = min(quadrangle_vertices[:,1])\n",
    "coord2max = max(quadrangle_vertices[:,1])\n",
    "    \n",
    "a = [coord1min, coord2min]\n",
    "c = [coord1max, coord2min]\n",
    "d = [coord1max, coord2max]\n",
    "b = [coord1min, coord2max]\n",
    "    \n",
    "four_points = [a,c,d,b]\n",
    "centre_x = 0.5*(coord1min + coord1max)\n",
    "centre_y = 0.5*(coord2min + coord2max)\n",
    "centre_xy = [int(centre_x), int(centre_y)]\n",
    "\n",
    "\n",
    "color = (0, 0, 0) \n",
    "thickness_poly = 5\n",
    "isClosed = True\n",
    "\n",
    "# Radius of circle \n",
    "radius = 5   \n",
    "# Blue color in BGR \n",
    "color = (0, 0, 0)    \n",
    "# Line thickness of 2 px \n",
    "thickness_circle = -1\n",
    "\n",
    "#to check whether the centre of the\n",
    "#rectangle lies with in the quadrangle\n",
    "\n",
    "\n",
    "img_lines_circle = imgrgb.copy()\n",
    "\n",
    "img_lines_circle = cv2.polylines(img_lines_circle, [quadrangle_vertices], isClosed, color, thickness_poly) \n",
    "\n",
    "center_coordinates = tuple(centre_xy)\n",
    "try:\n",
    "    img_lines_circle = cv2.circle(img_lines_circle, center_coordinates, radius, color, thickness_circle) \n",
    "except:\n",
    "    pass\n",
    "    \n",
    "\n",
    "imgD.plotImg(img_lines_circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following image shows the extent of warping (perspective transform) done by the Cam Scanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img from camscanner\n",
    "\n",
    "img_cs_file = '/Users/praneeth/Desktop/Image_Warping/Cam_Scanner/img05_cs.jpeg'\n",
    "\n",
    "farmWidth = 3.0 # meters\n",
    "tubenetPerMeter = 10 # meters\n",
    "\n",
    "imgD = ImageDetection(img_cs_file,farmWidth)\n",
    "img_cs = imgD.read(invert=False)\n",
    "imgrgb_cs = imgD.readRGB()\n",
    "scale = 1.0/4.0\n",
    "img_rs_cs = imgD.rescale(img_cs,scale)\n",
    "\n",
    "cs_temp = imgrgb_cs.shape[0]/imgrgb_cs.shape[1]\n",
    "asp_ratio_cs = max(cs_temp, 1/cs_temp)\n",
    "\n",
    "print('Aspect ratio using Cam Scanner')\n",
    "print(asp_ratio_cs)\n",
    "\n",
    "imgD.plotImg(imgrgb_cs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following image shows the extent of warping (perspective transform) done by Algo 1 which is based on the procedure outlined in this research paper incorporating concepts from linear algebraic transformations in vector spaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2004), Montreal, Quebec, 17â€“21 May, 2004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#warping using LINAL algo using sophisticated focal length & estimation of aspect ratio\n",
    "\n",
    "ordered_points = order_points(quadrangle_vertices)\n",
    "ordered_points_int = np.int32(ordered_points)\n",
    "asp_ratio_algo1_temp = asp_ratio(imgrgb, ordered_points_int, center_coordinates)[0]\n",
    "asp_ratio_algo1 = max(asp_ratio_algo1_temp, 1/asp_ratio_algo1_temp)\n",
    "warped_img_algo1 = asp_ratio(imgrgb, ordered_points_int, center_coordinates)[1]\n",
    "\n",
    "\n",
    "\n",
    "print('Aspect ratio using Algo 1')\n",
    "print(asp_ratio_algo1)\n",
    "imgD.plotImg(warped_img_algo1)\n",
    "\n",
    "#Yet to be incorporated\n",
    "#The printed values are the values of the focal length - focal length is not intended to be outputed by the algorithm\n",
    "#but the focal length is computed automatically by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following image shows the extent of warping (perspective transform) done by Algo 2 which is based on a simple rudimentary procedure in which there is no use of linear algebra techniques, but a common-sense approach of marking the extremities of the trapezium is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warping using simple algo\n",
    "\n",
    "ordered_points = order_points(quadrangle_vertices)\n",
    "ordered_points_int = np.int32(ordered_points)\n",
    "asp_ratio_algo2_temp = asp_ratio_simpler(imgrgb, ordered_points_int)[0]\n",
    "asp_ratio_algo2 = max(asp_ratio_algo2_temp, 1/asp_ratio_algo2_temp)\n",
    "warped_img_algo2 = asp_ratio_simpler(imgrgb, ordered_points_int)[1]\n",
    "\n",
    "\n",
    "print('Aspect ratio using Algo 2')\n",
    "print(asp_ratio_algo2)\n",
    "imgD.plotImg(warped_img_algo2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize = (25,25))\n",
    "   \n",
    "ax0 = fig.add_subplot(1,4,1)\n",
    "ax0.imshow(img_lines_circle)\n",
    "ax0.set_title('Original_Image')\n",
    "\n",
    "ax1 = fig.add_subplot(1,4,2)\n",
    "ax1.imshow(imgrgb_cs)\n",
    "ax1.set_title('Cam_scanner')\n",
    "\n",
    "\n",
    "ax2 = fig.add_subplot(1,4,3)\n",
    "ax2.imshow(warped_img_algo1)\n",
    "ax2.set_title('Algo_1')\n",
    "\n",
    "ax3 = fig.add_subplot(1,4,4)\n",
    "ax3.imshow(warped_img_algo2)\n",
    "ax3.set_title('Algo_2')\n",
    "\n",
    "\n",
    "\n",
    "ax0.set_xticks([])\n",
    "ax0.set_yticks([])\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables\n",
    "#Deriving a for loop of all the graphs\n",
    "\n",
    "num_images = 21\n",
    "\n",
    "asp_ratio_actual = np.ones(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.array([[58,291], [863, 267], [894,1100],[65,1100]], np.int32)\n",
    "\n",
    "q2 = np.array([[152, 281], [753, 262], [788,900], [133, 898]], np.int32)\n",
    "\n",
    "q3 = np.array([[218, 36], [743, 25], [769, 533], [190, 535]], np.int32)\n",
    "\n",
    "q4 = np.array([[292, 56], [629, 48], [657, 286], [247, 291]], np.int32)\n",
    "\n",
    "q5 = np.array([[324,5], [637,3], [656,198], [283,200]], np.int32)\n",
    "\n",
    "q6 = np.array([[228, 790], [395, 790], [391, 971], [216, 973]], np.int32)\n",
    "\n",
    "q7 = np.array([[303, 276], [505, 281], [501, 469], [289,458]], np.int32)\n",
    "\n",
    "q8 = np.array([[367, 28], [482, 28], [480,134], [364,136]], np.int32)\n",
    "\n",
    "q9 = np.array([[201, 195 ], [1130, 181     ], [ 1130, 1080     ],[222,1090     ]], np.int32)\n",
    "q10 = np.array([[120, 621    ], [747, 633      ], [ 730, 1290    ],[111,1265     ]], np.int32)\n",
    "q11 = np.array([[112, 108    ], [756, 141      ], [ 738, 815     ],[46, 782     ]], np.int32)\n",
    "q12 = np.array([[265, 261    ], [549, 274      ], [542, 564      ],[246, 541     ]], np.int32)\n",
    "\n",
    "q13 = np.array([[209, 234    ], [453, 240      ], [457, 493      ],[209, 487     ]], np.int32)\n",
    "q14 = np.array([[292, 361    ], [648, 377      ], [654, 760    ],[292, 737    ]], np.int32)\n",
    "q15 = np.array([[444, 511    ], [970, 515      ], [975, 1020    ],[434, 1020 ]], np.int32)\n",
    "q16 = np.array([[195, 212    ], [1220, 228     ], [1180, 1280   ],[120, 1240    ]], np.int32)\n",
    "\n",
    "q17 = np.array([[696, 181   ], [ 1605, 194   ], [ 1590, 1100  ],[679, 1070   ]], np.int32)\n",
    "q18 = np.array([[510, 139   ], [ 1380, 177   ], [ 1510, 1150  ],[548, 1040   ]], np.int32)\n",
    "q19 = np.array([[586, 176   ], [ 1460, 163   ], [ 1590, 1080  ],[660, 1030   ]], np.int32)\n",
    "q20 = np.array([[912, 1030   ], [1880, 1130    ], [1630, 2060   ],[749, 2050   ]], np.int32)\n",
    "q21 = np.array([[612, 562   ], [1370, 504    ], [1260, 1300  ],[455, 1370   ]], np.int32)\n",
    "\n",
    "\n",
    "q = [q1, q2, q3, q4, q5, q6, q7, q8, q9, q10, q11, q12, q13, q14, q15, q16, q17, q18, q19, q20, q21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "\n",
    "farmWidth = 3.0 # meters\n",
    "tubenetPerMeter = 10 # meters\n",
    "\n",
    "#Line variables (poly line enclosing)\n",
    "\n",
    "color = (0, 0, 0) \n",
    "thickness_poly = 5\n",
    "isClosed = True\n",
    "\n",
    "#Circle variables\n",
    "# Radius of circle \n",
    "radius = 5   \n",
    "# Blue color in BGR \n",
    "color = (0, 0, 0)    \n",
    "# Line thickness of 2 px \n",
    "thickness_circle = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/praneeth/Desktop/Image_Warping/Original'\n",
    "im_jpeg_locs = os.listdir(base_dir)\n",
    "original_img_locs = [os.path.join(base_dir,im_jpeg_loc) for im_jpeg_loc in im_jpeg_locs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global lists to which all will be appended\n",
    "\n",
    "imgrgb_overall = []\n",
    "img_lines_circle_overall = []\n",
    "center_coordinates_overall = []\n",
    "\n",
    "\n",
    "imgrgb_cs_overall = []\n",
    "asp_ratio_cs_overall = []\n",
    "\n",
    "ordered_points_int_overall = []\n",
    "\n",
    "asp_ratio_algo1_overall = []\n",
    "warped_img_algo1_overall = []\n",
    "\n",
    "asp_ratio_algo2_overall = []\n",
    "warped_img_algo2_overall = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_images):\n",
    "\n",
    "    #Original\n",
    "    imgD1 = ImageDetection(original_img_locs[i],farmWidth)\n",
    "    img = imgD1.read(invert=False)\n",
    "    imgrgb = imgD1.readRGB()\n",
    "\n",
    "\n",
    "    #Cam Scanner Image\n",
    "    imgD2 = ImageDetection(cs_img_locs[i],farmWidth)\n",
    "    img_cs = imgD2.read(invert=False)\n",
    "    imgrgb_cs = imgD2.readRGB()\n",
    "\n",
    "    cs_temp = imgrgb_cs.shape[0]/imgrgb_cs.shape[1]\n",
    "    asp_ratio_cs = max(cs_temp, 1/cs_temp)\n",
    "\n",
    "\n",
    "\n",
    "    #Quadrangle vertices & centre calculation\n",
    "    quadrangle_vertices = q[i]\n",
    "\n",
    "    coord1min = min(quadrangle_vertices[:,0])\n",
    "    coord1max = max(quadrangle_vertices[:,0])\n",
    "    coord2min = min(quadrangle_vertices[:,1])\n",
    "    coord2max = max(quadrangle_vertices[:,1])\n",
    "\n",
    "    a = [coord1min, coord2min]\n",
    "    c = [coord1max, coord2min]\n",
    "    d = [coord1max, coord2max]\n",
    "    b = [coord1min, coord2max]\n",
    "\n",
    "    four_points = [a,c,d,b]\n",
    "    centre_x = 0.5*(coord1min + coord1max)\n",
    "    centre_y = 0.5*(coord2min + coord2max)\n",
    "    centre_xy = [int(centre_x), int(centre_y)]\n",
    "\n",
    "    #Drawing img_lines_circle\n",
    "\n",
    "    img_lines_circle = imgrgb.copy()\n",
    "\n",
    "    img_lines_circle = cv2.polylines(img_lines_circle, [quadrangle_vertices], isClosed, color, thickness_poly) \n",
    "\n",
    "    center_coordinates = tuple(centre_xy)\n",
    "\n",
    "\n",
    "    try:\n",
    "        img_lines_circle = cv2.circle(img_lines_circle, center_coordinates, radius, color, thickness_circle) \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    ordered_points = order_points(quadrangle_vertices)\n",
    "    ordered_points_int = np.int32(ordered_points)\n",
    "    asp_ratio_algo1_temp = asp_ratio(imgrgb, ordered_points_int, center_coordinates)[0]\n",
    "    asp_ratio_algo1 = max(asp_ratio_algo1_temp, 1/asp_ratio_algo1_temp)\n",
    "    warped_img_algo1 = asp_ratio(imgrgb, ordered_points_int, center_coordinates)[1]\n",
    "\n",
    "    asp_ratio_algo2_temp = asp_ratio_simpler(imgrgb, ordered_points_int)[0]\n",
    "    asp_ratio_algo2 = max(asp_ratio_algo2_temp, 1/asp_ratio_algo2_temp)\n",
    "    warped_img_algo2 = asp_ratio_simpler(imgrgb, ordered_points_int)[1]\n",
    "\n",
    "\n",
    "    imgrgb_overall.append(imgrgb)\n",
    "    img_lines_circle_overall.append(img_lines_circle)\n",
    "    center_coordinates_overall.append(center_coordinates)\n",
    "\n",
    "    imgrgb_cs_overall.append(imgrgb_cs)\n",
    "    asp_ratio_cs_overall.append(asp_ratio_cs)\n",
    "\n",
    "    ordered_points_int_overall.append(ordered_points_int)\n",
    "\n",
    "    asp_ratio_algo1_overall.append(asp_ratio_algo1)\n",
    "    warped_img_algo1_overall.append(warped_img_algo1)\n",
    "\n",
    "    asp_ratio_algo2_overall.append(asp_ratio_algo2)\n",
    "    warped_img_algo2_overall.append(warped_img_algo2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following set of images demonstrate the three algorithms acting on the a set of 20 graph sheet photographs - (i) the Cam Scanner algorithm (ii) Algo 1 (based on LinAl techniques) (iii) Algo 2 (based on a simple common-sense approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows = num_images, ncols = 4, figsize = (60,180))\n",
    "\n",
    "\n",
    "#cols = ['Original Image', 'Cam Scanner warping', 'Algo1 warping', 'Algo2 warping']\n",
    "#rows = ['Row {}'.format(row) for row in np.arange(1,num_images +1)]\n",
    "\n",
    "\n",
    "#pad = 5\n",
    "\n",
    "#for ax_sp, col in zip(ax[0], cols):\n",
    "#    ax_sp.annotate(col, xy=(0.5, 1), xytext=(0, pad), xycoords='axes fraction', textcoords='offset points', size='large', ha='center', va='baseline')\n",
    "\n",
    "#for ax_sp, row in zip(ax[:,0], rows):\n",
    "#        ax_sp.annotate(row, xy=(0, 0.5), xytext=(-ax_sp.yaxis.labelpad - pad, 0), xycoords=ax_sp.yaxis.label, textcoords='offset points', size='large', ha='right', va='center')\n",
    "\n",
    "\n",
    "\n",
    "for i in range(num_images):\n",
    "    ax[i][0].imshow(img_lines_circle_overall[i], cmap = 'gray')\n",
    "    ax[i][0].set_title(asp_ratio_actual[i])\n",
    "    \n",
    "    ax[i][1].imshow(imgrgb_cs_overall[i], cmap = 'gray')\n",
    "    ax[i][1].set_title(asp_ratio_cs_overall[i])\n",
    "\n",
    "\n",
    "    ax[i][2].imshow(warped_img_algo1_overall[i], cmap = 'gray')\n",
    "    ax[i][2].set_title(asp_ratio_algo1_overall[i])\n",
    "\n",
    "\n",
    "    ax[i][3].imshow(warped_img_algo2_overall[i], cmap = 'gray')\n",
    "    ax[i][3].set_title(asp_ratio_algo2_overall[i])\n",
    "\n",
    "\n",
    "    \n",
    "    ax[i][0].axis('off')\n",
    "    ax[i][1].axis('off')\n",
    "    ax[i][2].axis('off')\n",
    "    ax[i][3].axis('off')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_tuples = list(zip(asp_ratio_actual,asp_ratio_cs_overall, asp_ratio_algo1_overall, asp_ratio_algo2_overall ))\n",
    "\n",
    "aspect_ratio = pd.DataFrame(data_tuples, columns=['Original Aspect Ratio','Cam Scanner AR', 'Algo 1 AR', 'Algo 2 AR'])  \n",
    "\n",
    "#percentage deviation from 1\n",
    "\n",
    "algocs_deviation = np.round(((asp_ratio_cs_overall - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "algo1_deviation = np.round(((asp_ratio_algo1_overall - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "algo2_deviation = np.round(((asp_ratio_algo2_overall - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "\n",
    "\n",
    "deviations_tuples = list(zip(algocs_deviation,algo1_deviation, algo2_deviation))\n",
    "\n",
    "deviations_dataframe = pd.DataFrame(deviations_tuples, columns=['Cam Scanner % deviation','Algo 1 % deviation', 'Algo 2 % deviation'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One can observe in the following graph that the aspect ratio deviations from 1.00 are least in the Cam Scanner, while Algo 1 and Algo 2 result in high deviations. However, the Algo 1 aspect ratio tends to deviate from 1.00 by a very high percentage for certain photographs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviations_dataframe.sort_values(by = 'Cam Scanner % deviation', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviations_dataframe.loc[:,['Algo 2 % deviation','Cam Scanner % deviation'] ].sort_values(by = 'Algo 2 % deviation', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#suspicious set\n",
    "\n",
    "ss = [4,12, 20, 5, 10, 19, 3,2,6]\n",
    "\n",
    "asp_ratio_actual = np.ones(len(ss))\n",
    "\n",
    "temp1 = [asp_ratio_cs_overall[val] for val in ss]\n",
    "temp2 = [asp_ratio_algo1_overall[val] for val in ss]\n",
    "temp3 = [asp_ratio_algo2_overall[val] for val in ss]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data_tuples = list(zip(ss, asp_ratio_actual,temp1, temp2, temp3 ))\n",
    "\n",
    "aspect_ratio = pd.DataFrame(data_tuples, columns=['index value','Original Aspect Ratio','Cam Scanner AR', 'Algo 1 AR', 'Algo 2 AR'])  \n",
    "\n",
    "#percentage deviation from 1\n",
    "\n",
    "algocs_deviation = np.round(((temp1 - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "algo1_deviation = np.round(((temp2 - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "algo2_deviation = np.round(((temp3 - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "\n",
    "\n",
    "deviations_tuples = list(zip(ss, algocs_deviation,algo1_deviation, algo2_deviation))\n",
    "\n",
    "deviations_dataframe = pd.DataFrame(deviations_tuples, columns=['index value', 'Cam Scanner % deviation','Algo 1 % deviation', 'Algo 2 % deviation'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deviations_dataframe.sort_values(by = 'Cam Scanner % deviation', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting of only suspicious images\n",
    "fig,ax = plt.subplots(nrows = 9, ncols = 4, figsize = (60,180))\n",
    "\n",
    "\n",
    "#for ax_sp, col in zip(ax[0], cols):\n",
    "#    ax_sp.annotate(col, xy=(0.5, 1), xytext=(0, pad), xycoords='axes fraction', textcoords='offset points', size='large', ha='center', va='baseline')\n",
    "\n",
    "#for ax_sp, row in zip(ax[:,0], rows):\n",
    "#        ax_sp.annotate(row, xy=(0, 0.5), xytext=(-ax_sp.yaxis.labelpad - pad, 0), xycoords=ax_sp.yaxis.label, textcoords='offset points', size='large', ha='right', va='center')\n",
    "\n",
    "\n",
    "for i,ssval in enumerate(ss):\n",
    "    ax[i][0].imshow(img_lines_circle_overall[ss_val], cmap = 'gray')\n",
    "    ax[i][0].set_title(str(1.0))\n",
    "    \n",
    "    ax[i][1].imshow(imgrgb_cs_overall[ss_val], cmap = 'gray')\n",
    "    ax[i][1].set_title(asp_ratio_cs_overall[ss_val])\n",
    "\n",
    "    ax[i][2].imshow(warped_img_algo1_overall[ss_val], cmap = 'gray')\n",
    "    ax[i][2].set_title(asp_ratio_algo1_overall[ss_val])\n",
    "\n",
    "    ax[i][3].imshow(warped_img_algo2_overall[ss_val], cmap = 'gray')\n",
    "    ax[i][3].set_title(asp_ratio_algo2_overall[ss_val])\n",
    "    \n",
    "    ax[i][0].axis('off')\n",
    "    ax[i][1].axis('off')\n",
    "    ax[i][2].axis('off')\n",
    "    ax[i][3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sensitivity\n",
    "\n",
    "\n",
    "i = 12\n",
    "qval = q[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "\n",
    "\n",
    "q_sa = [qval]\n",
    "\n",
    "\n",
    "for j in range(4):\n",
    "    qvalnew = qval.copy()\n",
    "    qvalnew[j] = np.array([qval[j][0] + 20, qval[j][1]], np.int32)\n",
    "    q_sa.append(qvalnew)\n",
    "    \n",
    "for j in range(4):\n",
    "    qvalnew = qval.copy()\n",
    "    qvalnew[j] = np.array([qval[j][0] - 20, qval[j][1]], np.int32)\n",
    "    q_sa.append(qvalnew)\n",
    "\n",
    "for j in range(4):\n",
    "    qvalnew = qval.copy()\n",
    "    qvalnew[j] = np.array([qval[j][0], qval[j][1]+20], np.int32)\n",
    "    q_sa.append(qvalnew)\n",
    "\n",
    "for j in range(4):\n",
    "    qvalnew = qval.copy()\n",
    "    qvalnew[j] = np.array([qval[j][0], qval[j][1] - 20], np.int32)\n",
    "    q_sa.append(qvalnew)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#Sensitivity analysis with specific i - original and cam scanner images\n",
    "\n",
    "\n",
    "#Original\n",
    "imgD1 = ImageDetection(original_img_locs[i],farmWidth)\n",
    "img = imgD1.read(invert=False)\n",
    "imgrgb = imgD1.readRGB()\n",
    "\n",
    "\n",
    "#Cam Scanner Image\n",
    "imgD2 = ImageDetection(cs_img_locs[i],farmWidth)\n",
    "img_cs = imgD2.read(invert=False)\n",
    "imgrgb_cs = imgD2.readRGB()\n",
    "\n",
    "cs_temp = imgrgb_cs.shape[0]/imgrgb_cs.shape[1]\n",
    "asp_ratio_cs = max(cs_temp, 1/cs_temp)\n",
    "\n",
    "#Global lists to which all will be appended\n",
    "\n",
    "img_lines_circle_sa = []\n",
    "center_coordinates_sa = []\n",
    "\n",
    "\n",
    "ordered_points_int_sa = []\n",
    "\n",
    "asp_ratio_algo1_sa= []\n",
    "warped_img_algo1_sa = []\n",
    "\n",
    "asp_ratio_algo2_sa = []\n",
    "warped_img_algo2_sa = []\n",
    "\n",
    "#Quadrangle vertices & centre calculation\n",
    "\n",
    "for j in range(len(q_sa)):\n",
    "\n",
    "    quadrangle_vertices = q_sa[j]\n",
    "\n",
    "    coord1min = min(quadrangle_vertices[:,0])\n",
    "    coord1max = max(quadrangle_vertices[:,0])\n",
    "    coord2min = min(quadrangle_vertices[:,1])\n",
    "    coord2max = max(quadrangle_vertices[:,1])\n",
    "\n",
    "    a = [coord1min, coord2min]\n",
    "    c = [coord1max, coord2min]\n",
    "    d = [coord1max, coord2max]\n",
    "    b = [coord1min, coord2max]\n",
    "\n",
    "    four_points = [a,c,d,b]\n",
    "    centre_x = 0.5*(coord1min + coord1max)\n",
    "    centre_y = 0.5*(coord2min + coord2max)\n",
    "    centre_xy = [int(centre_x), int(centre_y)]\n",
    "\n",
    "    #Drawing img_lines_circle\n",
    "\n",
    "    img_lines_circle = imgrgb.copy()\n",
    "\n",
    "    img_lines_circle = cv2.polylines(img_lines_circle, [quadrangle_vertices], isClosed, color, thickness_poly) \n",
    "\n",
    "    center_coordinates = tuple(centre_xy)\n",
    "\n",
    "\n",
    "    try:\n",
    "        img_lines_circle = cv2.circle(img_lines_circle, center_coordinates, radius, color, thickness_circle) \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    ordered_points = order_points(quadrangle_vertices)\n",
    "    ordered_points_int = np.int32(ordered_points)\n",
    "    asp_ratio_algo1_temp = asp_ratio(imgrgb, ordered_points_int, center_coordinates)[0]\n",
    "    asp_ratio_algo1 = max(asp_ratio_algo1_temp, 1/asp_ratio_algo1_temp)\n",
    "    warped_img_algo1 = asp_ratio(imgrgb, ordered_points_int, center_coordinates)[1]\n",
    "\n",
    "    asp_ratio_algo2_temp = asp_ratio_simpler(imgrgb, ordered_points_int)[0]\n",
    "    asp_ratio_algo2 = max(asp_ratio_algo2_temp, 1/asp_ratio_algo2_temp)\n",
    "    warped_img_algo2 = asp_ratio_simpler(imgrgb, ordered_points_int)[1]\n",
    "\n",
    "\n",
    "\n",
    "    img_lines_circle_sa.append(img_lines_circle)\n",
    "    center_coordinates_sa.append(center_coordinates)\n",
    "\n",
    "\n",
    "    ordered_points_int_sa.append(ordered_points_int)\n",
    "\n",
    "    asp_ratio_algo1_sa.append(asp_ratio_algo1)\n",
    "    warped_img_algo1_sa.append(warped_img_algo1)\n",
    "\n",
    "    asp_ratio_algo2_sa.append(asp_ratio_algo2)\n",
    "    warped_img_algo2_sa.append(warped_img_algo2)\n",
    "\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "asp_ratio_actual_sa = np.ones(len(q_sa))\n",
    "asp_ratio_cs_sa = asp_ratio_cs_overall[i]*np.ones(len(q_sa))\n",
    "\n",
    "data_tuples = list(zip(asp_ratio_actual_sa,asp_ratio_cs_sa, asp_ratio_algo1_sa, asp_ratio_algo2_sa ))\n",
    "\n",
    "aspect_ratio = pd.DataFrame(data_tuples, columns=['Original Aspect Ratio','Cam Scanner AR', 'Algo 1 AR', 'Algo 2 AR'])  \n",
    "\n",
    "#percentage deviation from 1\n",
    "\n",
    "algocs_dev_sa = np.round(((asp_ratio_cs_sa - asp_ratio_actual_sa)*100/asp_ratio_actual_sa),2)\n",
    "algo1_dev_sa = np.round(((asp_ratio_algo1_sa - asp_ratio_actual_sa)*100/asp_ratio_actual_sa),2)\n",
    "algo2_dev_sa = np.round(((asp_ratio_algo2_sa - asp_ratio_actual_sa)*100/asp_ratio_actual_sa),2)\n",
    "\n",
    "\n",
    "deviations_tuples = list(zip(algocs_dev_sa,algo1_dev_sa, algo2_dev_sa))\n",
    "\n",
    "deviations_dataframe = pd.DataFrame(deviations_tuples, columns=['Cam Scanner % deviation','Algo 1 % deviation', 'Algo 2 % deviation'])  \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviations_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This raises a question - in how many/which of the instances is the aspect ratio that we obtained a product of chance?\n",
    "\n",
    "#Original dataframe\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "asp_ratio_actual = np.ones(len(asp_ratio_cs_overall))\n",
    "\n",
    "data_tuples = list(zip(asp_ratio_actual,asp_ratio_cs_overall, asp_ratio_algo1_overall, asp_ratio_algo2_overall ))\n",
    "\n",
    "aspect_ratio = pd.DataFrame(data_tuples, columns=['Original Aspect Ratio','Cam Scanner AR', 'Algo 1 AR', 'Algo 2 AR'])  \n",
    "\n",
    "#percentage deviation from 1\n",
    "\n",
    "algocs_deviation = np.round(((asp_ratio_cs_overall - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "algo1_deviation = np.round(((asp_ratio_algo1_overall - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "algo2_deviation = np.round(((asp_ratio_algo2_overall - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "\n",
    "\n",
    "deviations_tuples = list(zip(algocs_deviation,algo1_deviation, algo2_deviation))\n",
    "\n",
    "deviations_dataframe = pd.DataFrame(deviations_tuples, columns=['Cam Scanner % deviation','Algo 1 % deviation', 'Algo 2 % deviation'])  \n",
    "\n",
    "#Original deviations dataframe\n",
    "deviations_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_augment(qval):\n",
    "    q_sa = [qval]\n",
    "\n",
    "    #only one coordinate at a time (x coordinate or y coordinate) is altered\n",
    "    for j in range(4):\n",
    "        qvalnew = qval.copy()\n",
    "        qvalnew[j] = np.array([qval[j][0] + 20, qval[j][1]], np.int32)\n",
    "        q_sa.append(qvalnew)\n",
    "\n",
    "    for j in range(4):\n",
    "        qvalnew = qval.copy()\n",
    "        qvalnew[j] = np.array([qval[j][0] - 20, qval[j][1]], np.int32)\n",
    "        q_sa.append(qvalnew)\n",
    "\n",
    "    for j in range(4):\n",
    "        qvalnew = qval.copy()\n",
    "        qvalnew[j] = np.array([qval[j][0], qval[j][1]+20], np.int32)\n",
    "        q_sa.append(qvalnew)\n",
    "\n",
    "    for j in range(4):\n",
    "        qvalnew = qval.copy()\n",
    "        qvalnew[j] = np.array([qval[j][0], qval[j][1] - 20], np.int32)\n",
    "        q_sa.append(qvalnew)\n",
    "\n",
    "    return(q_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Global lists to which all will be appended\n",
    "\n",
    "#center_coordinates_overall = []\n",
    "#ordered_points_int_overall = []\n",
    "\n",
    "ar_algo1_full_set = []\n",
    "\n",
    "ar_algo2_full_set = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    \n",
    "    \n",
    "    #Original Image\n",
    "    imgD1 = ImageDetection(original_img_locs[i],farmWidth)\n",
    "    img = imgD1.read(invert=False)\n",
    "    imgrgb = imgD1.readRGB()\n",
    "\n",
    "\n",
    "    ar_algo1_da = []\n",
    "    ar_algo2_da = []\n",
    "\n",
    "\n",
    "    #Quadrangle vertices & centre calculation\n",
    "    qval = q[i]\n",
    "    q_augment_set = q_augment(qval)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for quadrangle_vertices in q_augment_set:   \n",
    "        \n",
    "        coord1min = min(quadrangle_vertices[:,0])\n",
    "        coord1max = max(quadrangle_vertices[:,0])\n",
    "        coord2min = min(quadrangle_vertices[:,1])\n",
    "        coord2max = max(quadrangle_vertices[:,1])\n",
    "\n",
    "        a = [coord1min, coord2min]\n",
    "        c = [coord1max, coord2min]\n",
    "        d = [coord1max, coord2max]\n",
    "        b = [coord1min, coord2max]\n",
    "\n",
    "        four_points = [a,c,d,b]\n",
    "        centre_x = 0.5*(coord1min + coord1max)\n",
    "        centre_y = 0.5*(coord2min + coord2max)\n",
    "        centre_xy = [int(centre_x), int(centre_y)]\n",
    "\n",
    "        center_coordinates = tuple(centre_xy)\n",
    "        try:\n",
    "            ordered_points = order_points(quadrangle_vertices)\n",
    "            ordered_points_int = np.int32(ordered_points)\n",
    "            asp_ratio_algo1_temp = asp_ratio(imgrgb, ordered_points_int, center_coordinates)[0]\n",
    "            asp_ratio_algo1 = max(asp_ratio_algo1_temp, 1/asp_ratio_algo1_temp)\n",
    "            asp_ratio_algo2_temp = asp_ratio_simpler(imgrgb, ordered_points_int)[0]\n",
    "            asp_ratio_algo2 = max(asp_ratio_algo2_temp, 1/asp_ratio_algo2_temp)\n",
    "            \n",
    "            ar_algo1_da.append(asp_ratio_algo1)\n",
    "            ar_algo2_da.append(asp_ratio_algo2)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    ar_algo1_full_set.append([ar_algo1_da])\n",
    "    ar_algo2_full_set.append([ar_algo2_da])\n",
    "\n",
    "\n",
    "       \n",
    "  #  center_coordinates_overall.append(center_coordinates)\n",
    "\n",
    "   # ordered_points_int_overall.append(ordered_points_int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_algo1_full_set_squeezed = np.squeeze(ar_algo1_full_set)\n",
    "ar_algo1_max_estimate = [max(l) for l in ar_algo1_full_set_squeezed]\n",
    "\n",
    "ar_algo2_full_set_squeezed = np.squeeze(ar_algo2_full_set)\n",
    "ar_algo2_max_estimate = [max(l) for l in ar_algo2_full_set_squeezed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_tuples = list(zip(asp_ratio_actual,asp_ratio_cs_overall, asp_ratio_algo1_overall, asp_ratio_algo2_overall ))\n",
    "\n",
    "aspect_ratio_noda = pd.DataFrame(data_tuples, columns=['Original Aspect Ratio','Cam Scanner AR', 'Algo 1 AR', 'Algo 2 AR'])  \n",
    "\n",
    "#percentage deviation from 1\n",
    "\n",
    "algocs_deviation = np.round(((asp_ratio_cs_overall - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "algo1_deviation = np.round(((asp_ratio_algo1_overall - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "algo2_deviation = np.round(((asp_ratio_algo2_overall - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "\n",
    "\n",
    "deviations_tuples = list(zip(algocs_deviation,algo1_deviation, algo2_deviation))\n",
    "\n",
    "deviations_dataframe_noda = pd.DataFrame(deviations_tuples, columns=['Cam Scanner % deviation','Algo 1 % deviation', 'Algo 2 % deviation'])  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_tuples = list(zip(asp_ratio_actual,asp_ratio_cs_overall, ar_algo1_max_estimate, ar_algo2_max_estimate ))\n",
    "\n",
    "aspect_ratio_da = pd.DataFrame(data_tuples, columns=['Original Aspect Ratio','Cam Scanner AR', 'Algo 1 Max AR', 'Algo 2 Max AR'])  \n",
    "\n",
    "#percentage deviation from 1\n",
    "\n",
    "algocs_deviation = np.round(((asp_ratio_cs_overall - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "algo1_deviation = np.round(((ar_algo1_max_estimate - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "algo2_deviation = np.round(((ar_algo2_max_estimate - asp_ratio_actual)*100/asp_ratio_actual),2)\n",
    "\n",
    "\n",
    "deviations_tuples = list(zip(algocs_deviation,algo1_deviation, algo2_deviation))\n",
    "\n",
    "deviations_dataframe_da = pd.DataFrame(deviations_tuples, columns=['Cam Scanner % deviation','Max(Algo 1) % deviation', 'Max(Algo 2) % deviation'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)\n",
    "\n",
    "\n",
    "display_side_by_side(deviations_dataframe_noda.sort_values(by = 'Cam Scanner % deviation', ascending = False),deviations_dataframe_da.sort_values(by = 'Cam Scanner % deviation', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = deviations_dataframe_noda.sort_values(by = 'Cam Scanner % deviation', ascending = False)['Cam Scanner % deviation']\n",
    "algo1_dev = deviations_dataframe_noda.sort_values(by = 'Cam Scanner % deviation', ascending = False)['Algo 1 % deviation']\n",
    "algo1_maxdev = deviations_dataframe_da.sort_values(by = 'Cam Scanner % deviation', ascending = False)['Max(Algo 1) % deviation']\n",
    "\n",
    "\n",
    "cs_old = cs\n",
    "algo1_dev_old = algo1_dev\n",
    "algo1_maxdev_old = algo1_maxdev\n",
    "\n",
    "cs = cs.reset_index(drop = True)\n",
    "algo1_dev_old = algo1_dev_old.reset_index(drop = True)\n",
    "algo1_maxdev = algo1_maxdev.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to understand the high degrees of deviations from 1.00 observed for Algo 1, it was speculated that errors in the identification of the four corners of the quadrangle might have an impact in blowing up the deviations from 1.00. So in order to simulate the incorrect annotation, for the same image, the four corners of the quadrangle were annotated (around a radius of 5 pixels about the actual corner). This procedure was repeated for all the 20 photographs of the graph sheets, which resulted in an estimate for the maximum variability of the aspect ratio from 1.00 as observed in the following graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(1,1)\n",
    "\n",
    "plt.plot(cs, 'r.', label = 'Cam scanner')\n",
    "plt.plot(cs, 'r')\n",
    "\n",
    "\n",
    "plt.plot(algo1_dev, 'g+',  label = 'Algo1')\n",
    "#plt.plot(algo1_dev, 'g')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(algo1_maxdev, 'k*', label = 'Algo1 max')\n",
    "#plt.plot(algo1_maxdev, 'k')\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks([])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
